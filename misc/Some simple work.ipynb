{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "USE_CUDA = False\n",
    "DATA = \"/home/hq/data/machine_translation\"\n",
    "#comment out the above line and use the line below to run remotely\n",
    "DATA = \".\"\n",
    "reconstruct = True\n",
    "NGRAM = True\n",
    "ORDER = 1\n",
    "NESTED = True\n",
    "MAX_LENGTH = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def ngram_helper(length,order):\n",
    "    result = 0\n",
    "    for i in range(1,order + 1):\n",
    "        result += length - (i - 1)\n",
    "    return result\n",
    "\n",
    "MAX_LENGTH_2 = ngram_helper(MAX_LENGTH,ORDER)\n",
    "print(MAX_LENGTH_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence', 'index']\n",
      "['this is sentence 1', 'hello world']\n",
      "Processed 1 lines so far..\n",
      "['this is sentence 2', 'a dog likes to bite a cat']\n",
      "['this is sentence 3', 'an elephant will be shot to death']\n",
      "odict_keys(['hello', 'world', 'likes', 'cat', 'bite', 'a', 'to', 'dog', 'death', 'an', 'elephant', 'be', 'will', 'shot'])\n",
      "odict_values([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1])\n",
      "['hello', 'world', 'likes', 'cat', 'bite', 'a', 'to', 'dog', 'death', 'an', 'elephant', 'be', 'will', 'shot']\n",
      "['apple', 'pear']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "def extract_ngrams(vocab, sent, order=1):\n",
    "    # tokenization\n",
    "    uwords = [t.text for t in nlp((sent))]\n",
    "    for oo in range(1,order+1):\n",
    "        for ng in set([' '.join(t).strip() for t in zip(*[uwords[i:] for i in range(oo)])]):\n",
    "            if ng in vocab:\n",
    "                vocab[ng] += 1\n",
    "            else:\n",
    "                vocab[ng] = 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def _read(source, saveto, order=3):\n",
    "\n",
    "    vocab0 = OrderedDict()\n",
    "\n",
    "    with open(source, 'r') as f:\n",
    "        header = f.readline()\n",
    "        cols = [c.strip() for c in header.split('\\t')]\n",
    "        print(cols)\n",
    "        for li, line in enumerate(f):\n",
    "            cols = [c.strip() for c in line.split('\\t')]\n",
    "            print(cols)\n",
    "            vocab0 = extract_ngrams(vocab0, cols[1].lower(), order=order)\n",
    "\n",
    "            if np.mod(li, 100) == 0:\n",
    "                print ('Processed {} lines so far..'.format(li+1))\n",
    "\n",
    "    tokens = vocab0.keys()\n",
    "    freqs = vocab0.values()\n",
    "    print(tokens)\n",
    "    print(freqs)\n",
    "    result = list(tokens)\n",
    "    print(result)\n",
    "    return result\n",
    "    #sidx = np.argsort(freqs)[::-1]\n",
    "    #print(sidx)\n",
    "    #vocab = OrderedDict([(tokens[s],i+1) for i, s in enumerate(sidx)])\n",
    "\n",
    "result = _read(\"./test.txt\",None,1)\n",
    "\n",
    "    \n",
    "\n",
    "a = {}\n",
    "a[\"apple\"] = 1\n",
    "a[\"pear\"] = 2\n",
    "print(list(a.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "class Lang_ngram:\n",
    "    def __init__(self, name,order = ORDER):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "        self.order = order\n",
    "    def extract_ngrams(self,sent):\n",
    "        local_ngram = []\n",
    "        uwords = [t.text for t in nlp((sent))]\n",
    "        for oo in range(1,self.order + 1):\n",
    "            for ng in set([' '.join(t).strip() for t in zip(*[uwords[i:] for i in range(oo)])]):\n",
    "                if ng not in self.word2index:\n",
    "                    self.word2index[ng] = self.n_words\n",
    "                    self.word2count[ng] = 1\n",
    "                    self.index2word[self.n_words] = ng\n",
    "                    self.n_words +=1\n",
    "                else:\n",
    "                    self.word2count[ng] += 1\n",
    "                local_ngram.append(ng)\n",
    "        local_ngram = set(local_ngram)\n",
    "        return local_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=True, ngram = NGRAM):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(DATA + '/%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse and not ngram:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    elif not reverse and ngram:\n",
    "        input_lang = Lang_ngram(lang1,order = ORDER)\n",
    "        output_lang = Lang(lang1)\n",
    "    elif reverse and ngram:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang_ngram(lang2,order = ORDER)\n",
    "        output_lang = Lang(lang2)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) <= MAX_LENGTH and len(p[1].split(' ')) <= MAX_LENGTH #and \\\n",
    "        #p[0].startswith(good_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 149861 sentence pairs\n",
      "Trimmed to 28 sentence pairs\n",
      "Indexing words & ngrams...\n",
      "collecting 21 of n grams, of n <= 1\n",
      "\n",
      "[{'!', 'terrific'}, 'terrific !']\n",
      "<__main__.Lang_ngram object at 0x7f97ccb4cd68>\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=True,ngram = NGRAM):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse, ngram)\n",
    "    if ngram:\n",
    "        gram_word_pairs = []\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    if not ngram:\n",
    "        print(\"Indexing words...\")\n",
    "    else:\n",
    "        print(\"Indexing words & ngrams...\")\n",
    "    for pair in pairs:\n",
    "        if not ngram:\n",
    "            input_lang.index_words(pair[0])\n",
    "            output_lang.index_words(pair[1])\n",
    "        else:\n",
    "            n_gram = input_lang.extract_ngrams(pair[0])\n",
    "            output_lang.index_words(pair[0])\n",
    "            gram_word_pairs.append([n_gram,pair[0]]) #n_gram is a list of strings, yet pair[0] is a string!\n",
    "    if ngram:\n",
    "        pairs = gram_word_pairs\n",
    "        print(\"collecting {} of n grams, of n <= {}\\n\".format(len(input_lang.word2index.keys()),input_lang.order))\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', reverse = False, ngram = NGRAM)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))\n",
    "print(input_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'!', 'wait'}, 'wait !']\n",
      "[[{'go', '.'}, 'go .'], [{'!', 'run'}, 'run !'], [{'!', 'run'}, 'run !'], [{'.', 'jump'}, 'jump .'], [{'!', 'stop'}, 'stop !'], [{'!', 'wait'}, 'wait !'], [{'!', 'wait'}, 'wait !'], [{'!', 'attack'}, 'attack !'], [{'!', 'attack'}, 'attack !'], [{'!', 'cheers'}, 'cheers !'], [{'!', 'cheers'}, 'cheers !'], [{'.', 'listen'}, 'listen .'], [{'?', 'really'}, 'really ?'], [{'?', 'really'}, 'really ?'], [{'thanks', '.'}, 'thanks .'], [{'!', 'awesome'}, 'awesome !'], [{'!', 'perfect'}, 'perfect !'], [{'!', 'terrific'}, 'terrific !'], [{'!', 'terrific'}, 'terrific !'], [{'!', 'terrific'}, 'terrific !'], [{'!', 'fantastic'}, 'fantastic !'], [{'seriously', '?'}, 'seriously ?'], [{'seriously', '?'}, 'seriously ?'], [{'!', 'wonderful'}, 'wonderful !'], [{'unbelievable', '!'}, 'unbelievable !'], [{'!', 'congratulations'}, 'congratulations !'], [{'!', 'congratulations'}, 'congratulations !'], [{'!', 'congratulations'}, 'congratulations !']]\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "def indexes_from_sentence_ngram(lang,sentence):\n",
    "    #print(type(sentence))\n",
    "    #print(type(list(sentence)))\n",
    "    return [lang.word2index[word] for word in list(sentence)]\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     print('var =', var)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "def variable_from_sentence_ngram(lang,sentence):\n",
    "    indexes = indexes_from_sentence_ngram(lang,sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1,1))\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "def variables_from_pair(pair,ngram = NGRAM):\n",
    "    if ngram:\n",
    "        input_variable = variable_from_sentence_ngram(input_lang,pair[0])\n",
    "        target_variable = variable_from_sentence(output_lang,pair[1])\n",
    "    else:\n",
    "        input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "        target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        print(word_inputs.size())\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderWithoutPortfolio(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderWithoutPortfolio, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        print(\"encoder input size is {}\".format(self.input_size))\n",
    "\n",
    "    def forward(self, word_inputs,hidden):\n",
    "        #print(\"ENCODER INPUT SIZE\",self.input_size)\n",
    "        seq_len = len(word_inputs)\n",
    "        #print(\"seq length is\",seq_len)\n",
    "        #print(word_inputs.data)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len,1,-1)\n",
    "        hidden = torch.mean(embedded,dim = 0)\n",
    "        #embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        hidden = torch.stack((hidden,hidden))\n",
    "        \n",
    "        return embedded, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = GeneralAttn(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step, but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "        print(\"sequence length in the attention module is\",seq_len)\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        #print(\"the dimension of attn_energies is\",attn_energies.shape)\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies,dim = 0).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        #print(\"HEY\")\n",
    "        #print(\"rnn input size for decoder is{}, last_hidden size for decoder is{}\".format(rnn_input.size(),last_hidden.size()))\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)),dim = 1)\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_Ngram(nn.Module):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input size is 10\n",
      "EncoderWithoutPortfolio(\n",
      "  (embedding): Embedding(10, 10)\n",
      ")\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, dropout=0.1)\n",
      "  (out): Linear(in_features=20, out_features=10)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=10, out_features=10)\n",
      "  )\n",
      ")\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "#encoder_test = EncoderRNN(10,10,2)\n",
    "encoder_test = EncoderWithoutPortfolio(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input size is 23\n"
     ]
    }
   ],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "#encoder = EncoderRNN(input_lang.n_words,hidden_size,n_layers)\n",
    "encoder = EncoderWithoutPortfolio(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "#n_epochs = 50000\n",
    "#plot_every = 200\n",
    "#print_every = 1000\n",
    "n_epochs = 100\n",
    "plot_every = 2\n",
    "print_every = 10\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 1s (- 0m 15s) (10 10%) 3.1335\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 3s (- 0m 12s) (20 20%) 2.6251\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 4s (- 0m 9s) (30 30%) 2.1814\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 5s (- 0m 8s) (40 40%) 1.9100\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 7s (- 0m 7s) (50 50%) 1.7603\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 8s (- 0m 5s) (60 60%) 1.6259\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 10s (- 0m 4s) (70 70%) 1.6037\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 11s (- 0m 2s) (80 80%) 1.4385\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 12s (- 0m 1s) (90 90%) 1.2104\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "sequence length in the attention module is 3\n",
      "0m 14s (- 0m 0s) (100 100%) 1.1755\n"
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97d81c5390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSqkApMldKaUCkCZ3pZQKQP8PkWTVzwNaQTcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97ccb93128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH,ngram = NGRAM,test = False):\n",
    "    if ngram and not test:\n",
    "        input_variable = variable_from_sentence_ngram(input_lang,sentence)\n",
    "    elif ngram and test:\n",
    "        sentence = input_lang.extract_ngrams(sentence)\n",
    "        input_variable = variable_from_sentence_ngram(input_lang,sentence)\n",
    "    else:\n",
    "        input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, MAX_LENGTH_2+1)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        processed_attn = decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "        print(processed_attn.shape)\n",
    "        print(decoder_attentions.shape)\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += processed_attn\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "> {'thanks', '.'}\n",
      "= thanks .\n",
      "< . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "! !\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAECCAYAAADelD2uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97d8b188d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\"attack !\",test = True)\n",
    "plt.matshow(attentions.numpy())\n",
    "output_sentence = ' ' .join(output_words)\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence,test = True):\n",
    "    output_words, attentions = evaluate(input_sentence,test = test)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    show_attention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "input = attack !\n",
      "output = ! !\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEGCAYAAADR49ZKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBOCa/WsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97c84975f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"attack !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "input = terrific .\n",
      "output = . .\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAEGCAYAAAA+Ib10AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwSpJjRmsktSYwSpJjf0/G4ZWgMupGsIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97c83d51d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "evaluate_and_show_attention(\"terrific .\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "sequence length in the attention module is 3\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "input = stop jump\n",
      "output = seriously <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEDCAYAAAA849PJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97c8773d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"stop jump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
